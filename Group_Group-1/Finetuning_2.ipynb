{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE:\n",
        "**Output cells are intentionally omitted in this repository** to prevent display corruption or issues.\n",
        "Run this notebook in Colab/Kaggle to see live outputs."
      ],
      "metadata": {
        "id": "97Z5W3XsA-79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clears all outputs to prevent corruption\n",
        "from google.colab import output\n",
        "output.clear()"
      ],
      "metadata": {
        "id": "9WS2tuKLBsaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9F9meeQYh0F"
      },
      "outputs": [],
      "source": [
        "!pip -q install transformers torch sentencepiece pandas evaluate accelerate rouge_score wandb bert_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import evaluate\n",
        "import os\n",
        "import wandb\n",
        "\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
        "from peft import LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "_ehMC4XCYuxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"iqballx/indonesian_news_datasets\",\n",
        "                       data_files=\"data.csv\",\n",
        "                       split=\"train\")"
      ],
      "metadata": {
        "id": "bRoNM0raY2JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(dataset)"
      ],
      "metadata": {
        "id": "M6NgC37nfoDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.features)"
      ],
      "metadata": {
        "id": "sah26QRRtIJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_test = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_val = train_test[\"train\"].train_test_split(test_size=0.125, seed=42)\n",
        "\n",
        "# Final splits\n",
        "train_dataset = train_val[\"train\"]\n",
        "val_dataset = train_val[\"test\"]  # This becomes validation\n",
        "test_dataset = train_test[\"test\"]  # This becomes test\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "w57PZ738t1q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"cahya/t5-base-indonesian-summarization-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "t2Rc7evBakoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "  # Handle batched input explicitly\n",
        "  content_list = examples[\"content\"]\n",
        "  summary_list = examples[\"summary\"]\n",
        "\n",
        "  # Ensure all entries are strings\n",
        "  content_list = [str(content) if content is not None else \"\" for content in content_list]\n",
        "  summary_list = [str(summary) if summary is not None else \"\" for summary in summary_list]\n",
        "\n",
        "  # Add T5 prefix for summarization task\n",
        "  prefixed_content = [f\"summarize: {content}\" for content in content_list]\n",
        "\n",
        "  inputs = tokenizer(\n",
        "    prefixed_content,\n",
        "    max_length=1024,\n",
        "    truncation=True,\n",
        "    padding=False\n",
        "  )\n",
        "\n",
        "  targets = tokenizer(\n",
        "    summary_list,\n",
        "    max_length=512,\n",
        "    truncation=True,\n",
        "    padding=False\n",
        "  )\n",
        "\n",
        "  inputs['labels'] = targets['input_ids']\n",
        "  return inputs"
      ],
      "metadata": {
        "id": "GKwtxTIciaIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "HpJKfD0lsXnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "  r=8,                    # Low rank for efficiency\n",
        "  lora_alpha=32,          # Higher alpha for r=8\n",
        "  lora_dropout=0.1,       # Moderate regularization\n",
        "  bias=\"none\",            # Preserve original bias behavior\n",
        "  task_type=\"SEQ_2_SEQ_LM\",  # For T5 summarization\n",
        "  target_modules=[\"q\", \"v\", \"k\", \"o\", \"DenseReluDense.wi\", \"DenseReluDense.wo\"]  # Key T5 layers\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "u4wQ5O_guIiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "vIqqx2uAu0VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_api_key = userdata.get('WANDB_API_KEY')\n",
        "\n",
        "if not wandb_api_key:\n",
        "  print('Wandb API key not found in environment variables!')\n",
        "else:\n",
        "  wandb.login(key=wandb_api_key)"
      ],
      "metadata": {
        "id": "Uv7Kicsvu_qO",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb_entity = userdata.get('WANDB_ENTITY')\n",
        "\n",
        "if not wandb_entity:\n",
        "  wandb_entity = input(\"Enter wandb entity name: \")\n",
        "else:\n",
        "  wandb.init(\n",
        "    project=\"trustify\",\n",
        "    entity=wandb_entity,\n",
        "    config={\n",
        "      \"epochs\": 3,\n",
        "      \"batch_size\": 8,\n",
        "      \"lr\": 3e-4\n",
        "    }\n",
        "  )"
      ],
      "metadata": {
        "id": "CJj2t9YkvRZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "  output_dir=\"./t5_results\",\n",
        "  num_train_epochs=3,\n",
        "  per_device_train_batch_size=4,\n",
        "  per_device_eval_batch_size=4,\n",
        "  warmup_steps=500,\n",
        "  weight_decay=0.01,\n",
        "  logging_dir=\"./t5_logs\",\n",
        "  logging_steps=10,\n",
        "  learning_rate=3e-4,\n",
        "  report_to=[\"wandb\"],\n",
        "  save_steps=500,  # Save every 500 steps\n",
        "  eval_steps=500,  # Evaluate every 500 steps (matching save_steps)\n",
        "  save_total_limit=2,\n",
        "  load_best_model_at_end=True,\n",
        "  metric_for_best_model=\"eval_loss\",\n",
        "  greater_is_better=False,\n",
        "  # T5-specific additions\n",
        "  gradient_accumulation_steps=2,\n",
        "  fp16=True,\n",
        "  dataloader_num_workers=2,\n",
        "  # Align evaluation and save strategy\n",
        "  eval_strategy=\"steps\",  # Changed from default \"no\"\n",
        "  save_strategy=\"steps\",        # Explicitly set to match evaluation\n",
        "  # Label smoothing for T5's generation tasks\n",
        "  label_smoothing_factor=0.1,\n",
        "  # Gradient clipping for stability\n",
        "  max_grad_norm=1.0,\n",
        "  # Learning rate scheduler\n",
        "  lr_scheduler_type=\"linear\",\n",
        ")"
      ],
      "metadata": {
        "id": "FwtRzeLTrA24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for T5\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "  tokenizer=tokenizer,\n",
        "  model=model,\n",
        "  padding=True,  # Dynamic padding to longest sequence in batch\n",
        "  pad_to_multiple_of=8,  # Optimize for GPU memory alignment\n",
        "  return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "j3qFMU6asF3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your trainer configuration\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,  # Use validation set for evaluation\n",
        "    data_collator=data_collator,  # Essential for proper batching\n",
        ")"
      ],
      "metadata": {
        "id": "54OdUjddsRZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "2eDu5g-6xO9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import evaluate\n",
        "\n",
        "# Load both metrics\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "bertscore = evaluate.load(\"bertscore\")\n",
        "\n",
        "# Limit evaluation to first 300 samples for efficiency\n",
        "eval_limit = 300\n",
        "test_subset = test_dataset.select(range(eval_limit))\n",
        "\n",
        "generated_summaries = []\n",
        "\n",
        "# Generate summaries for limited subset\n",
        "for i in range(len(test_subset)):\n",
        "    input_ids = torch.tensor(test_subset[i][\"input_ids\"]).unsqueeze(0)\n",
        "\n",
        "    # Move input_ids to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        input_ids = input_ids.to('cuda')\n",
        "\n",
        "    # Generate summary\n",
        "    generated_ids = model.generate(input_ids=input_ids, max_length=128)\n",
        "\n",
        "    # Decode the generated summary\n",
        "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "    generated_summaries.append(generated_text)\n",
        "\n",
        "# Prepare reference summaries\n",
        "reference_summaries = []\n",
        "for i in range(len(test_subset)):\n",
        "    # Replace -100 with pad_token_id for proper decoding\n",
        "    labels = test_subset[i][\"labels\"]\n",
        "    labels = [token_id if token_id != -100 else tokenizer.pad_token_id for token_id in labels]\n",
        "    reference_text = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "    reference_summaries.append(reference_text)\n",
        "\n",
        "# Calculate both metrics\n",
        "rouge_scores = rouge.compute(predictions=generated_summaries, references=reference_summaries)\n",
        "bertscore_scores = bertscore.compute(\n",
        "    predictions=generated_summaries,\n",
        "    references=reference_summaries,\n",
        "    lang=\"id\"\n",
        ")"
      ],
      "metadata": {
        "id": "BVPlc500dtas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
        "print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
        "print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n",
        "print(f\"BERTScore F1: {sum(bertscore_scores['f1']) / len(bertscore_scores['f1']):.4f}\")"
      ],
      "metadata": {
        "id": "FBwAGWerfm7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretation\n",
        "\n",
        "**ROUGE Scores Analysis:**\n",
        "- **ROUGE-1 (0.5161):** Moderate unigram overlap between generated and reference summaries (51.6% of words match)\n",
        "- **ROUGE-2 (0.3154):** Lower bigram overlap (31.5% of word pairs match), indicating some phrase disruption\n",
        "- **ROUGE-L (0.4207):** 42.1% of longest common subsequence matches, showing reasonable structural alignment\n",
        "\n",
        "**BERTScore Analysis:**\n",
        "- **BERTScore F1 (0.7955):** High semantic similarity (79.5%), indicating generated summaries capture meaning well despite surface-level differences\n",
        "\n",
        "**Interpretation:**\n",
        "- **Good semantic quality:** BERTScore suggests summaries preserve meaning effectively\n",
        "- **Moderate lexical precision:** ROUGE scores indicate reasonable word choice but potential paraphrasing\n",
        "- **Phrase-level challenges:** Lower ROUGE-2 suggests some disruption in phrase structure\n",
        "- **Overall positive:** BERTScore significantly higher than ROUGE indicates good meaning preservation despite different wording\n",
        "\n",
        "**Quality Assessment:**\n",
        "The model produces summaries that capture the core meaning (high BERTScore) but often uses different wording than references (lower ROUGE). This suggests good abstractive capabilities rather than simple copying, which is desirable for summarization. The 0.7955 BERTScore indicates strong semantic alignment with reference summaries, suggesting quality output for Indonesian summarization."
      ],
      "metadata": {
        "id": "bRldYqVGqZou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Store evaluation results in wandb\n",
        "wandb.log({\n",
        "    \"eval_rouge1\": rouge_scores[\"rouge1\"],\n",
        "    \"eval_rouge2\": rouge_scores[\"rouge2\"],\n",
        "    \"eval_rougeL\": rouge_scores[\"rougeL\"],\n",
        "    \"eval_bertscore_f1\": sum(bertscore_scores['f1']) / len(bertscore_scores['f1'])\n",
        "})"
      ],
      "metadata": {
        "id": "gpOUXKrQd0Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save PEFT adapters after training\n",
        "trainer.save_model(\"./t5_lora_adapters\")\n",
        "\n",
        "# Create wandb artifact for PEFT adapters\n",
        "lora_artifact = wandb.Artifact(\n",
        "    name=f\"t5-indonesian-lora-{wandb.run.id}\",\n",
        "    type=\"model\",\n",
        "    description=\"LoRA adapter weights for Indonesian summarization model\",\n",
        "    metadata={\n",
        "        \"architecture\": \"t5\",\n",
        "        \"peft_method\": \"lora\",\n",
        "        \"training_epochs\": 3,\n",
        "        \"batch_size\": 4,\n",
        "        \"learning_rate\": 3e-4,\n",
        "        \"final_train_loss\": trainer.state.log_history[-1][\"train_loss\"] if trainer.state.log_history else None,\n",
        "        \"rouge1_f1\": rouge_scores[\"rouge1\"],\n",
        "        \"rouge2_f1\": rouge_scores[\"rouge2\"],\n",
        "        \"rougeL_f1\": rouge_scores[\"rougeL\"],\n",
        "        \"bertscore_f1\": sum(bertscore_scores['f1']) / len(bertscore_scores['f1'])\n",
        "    }\n",
        ")\n",
        "\n",
        "lora_artifact.add_dir(\"./t5_lora_adapters\")\n",
        "wandb.log_artifact(lora_artifact)\n",
        "\n",
        "print(f\"LoRA adapters saved as artifact: {lora_artifact.name}\")"
      ],
      "metadata": {
        "id": "3nYukEz9osD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_summarization(input_text, max_input_length=512, max_output_length=128):\n",
        "    \"\"\"\n",
        "    Generate summary for a given input text using the trained model.\n",
        "    \"\"\"\n",
        "    # Tokenize input text\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Move to GPU if available\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
        "\n",
        "    # Generate summary\n",
        "    with torch.no_grad():\n",
        "        generated_ids = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=max_output_length,\n",
        "            num_beams=4,  # Use beam search for better quality\n",
        "            length_penalty=2.0,  # Penalize longer sequences\n",
        "            early_stopping=True,\n",
        "            no_repeat_ngram_size=2  # Prevent repetitive n-grams\n",
        "        )\n",
        "\n",
        "    # Decode generated summary\n",
        "    generated_summary = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_summary\n",
        "\n",
        "def interactive_summarization_loop():\n",
        "    \"\"\"\n",
        "    Interactive loop for manual summarization testing with user input.\n",
        "    \"\"\"\n",
        "    print(\"Interactive Summarization Testing\")\n",
        "    print(\"Enter text to summarize (type 'quit' to exit):\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nEnter text: \").strip()\n",
        "\n",
        "            if user_input.lower() == 'quit':\n",
        "                print(\"Exiting summarization loop.\")\n",
        "                break\n",
        "\n",
        "            if not user_input:\n",
        "                print(\"Please enter valid text.\")\n",
        "                continue\n",
        "\n",
        "            # Generate summary\n",
        "            summary = test_summarization(user_input)\n",
        "\n",
        "            print(f\"\\nGenerated Summary: {summary}\")\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nInterrupted by user. Exiting.\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Error during summarization: {e}\")\n",
        "            continue\n",
        "\n",
        "# Uncomment to run interactive testing\n",
        "interactive_summarization_loop()"
      ],
      "metadata": {
        "id": "W1UROQ4Lo5nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input:\n",
        "\n",
        "> REPUBLIKA.CO.ID, WASHINGTON -- Arab Saudi dan Amerika Serikat (AS) menandatangani serangkaian perjanjian penting di Washington pada Selasa (18/11/2025). Perjanjian tersebut menggarisbawahi kemitraan strategis dalam kecerdasan buatan (AI) dan pernyataan bersama yang menandai selesainya negosiasi mengenai kerja sama nuklir sipil.  Perjanjian tersebut mencerminkan peningkatan signifikan dalam kerja sama teknologi dan ekonomi antara kedua negara, khususnya di bidang industri maju, keamanan energi, dan teknologi baru. Bersamaan dengan kerangka kerja AI dan nuklir, kedua belah pihak mendukung pengaturan baru untuk memperkuat ketahanan rantai pasokan untuk uranium, mineral penting, dan magnet permanen, serta inisiatif untuk mempercepat investasi Saudi di Amerika Serikat dan memperluas kerja sama keuangan, ekonomi, pendidikan, dan regulasi.  Selama pertemuan puncak tersebut, Putra Mahkota dan Perdana Menteri Saudi, Mohammed bin Salman (MBS) dan Presiden AS Donald Trump meninjau hubungan bilateral dan membahas cara-cara untuk meningkatkan kemitraan strategis Saudi–AS di seluruh sektor prioritas.  Seperti dilaporkan Saudi Gazette, mereka juga bertukar pandangan mengenai perkembangan regional dan internasional dengan penekanan pada penguatan keamanan, stabilitas, dan pertumbuhan ekonomi.  Presiden Trump secara resmi menyambut Putra Mahkota di Gedung Putih dengan upacara lengkap yang meliputi pengawalan kavaleri, penghormatan 19 senjata, band militer yang membawakan lagu kebangsaan Saudi dan Amerika, serta pertunjukan pesawat tempur untuk menghormati kunjungan tersebut.  Kedua pemimpin kemudian mengunjungi beberapa bagian Gedung Putih sebelum memulai pembicaraan resmi mereka.  Delegasi Arab Saudi terdiri dari Menteri Energi dan Ketua Komite Kemitraan Ekonomi Strategis Saudi–AS Pangeran Abdulaziz bin Salman, Duta Besar Saudi untuk Amerika Serikat Putri Reema binti Bandar, Menteri Luar Negeri Pangeran Faisal bin Farhan, Penasihat Keamanan Nasional Musaed Al-Aiban, Menteri Perdagangan Majid Al-Qasabi, Menteri Keuangan Mohammed Al-Jadaan, dan Gubernur Dana Investasi Publik Yasir Al-Rumayyan.  Dari pihak AS, peserta meliputi Wakil Presiden JD Vance, Menteri Luar Negeri Marco Rubio, Menteri Perang Pete Hegseth, Menteri Keuangan Scott Bessent, Menteri Energi Chris Wright, Kepala Staf Gedung Putih Susie Wiles, dan Utusan Khusus untuk Timur Tengah Steve Witkoff.\n",
        "\n",
        "Generated Summary:\n",
        "\n",
        "> Arab Saudi dan AS menandatangani serangkaian perjanjian penting di Washington pada Selasa( 18/11/2025). Perjanjian tersebut menggarisbawahi kemitraan strategis dalam kecerdasan buatan( AI) dan pernyataan bersama yang menandai selesainya negosiasi mengenai kerja sama nuklir sipil. Kedua belah pihak mendukung pengaturan baru untuk memperkuat ketahanan rantai pasokan untuk uranium, mineral penting, dan magnet permanen, serta inisiatif untuk mempercepat investasi Saudi di Amerika Serikat. Pertemuan puncak tersebut, Putra Mahkota dan Perdana Menteri Saudi, Mohammed bin Salman( MBS) serta Presiden AS Donald Trump meninjau hubungan bilateral dan membahas cara- cara untuk meningkatkan kemitraan strategik Saudi– AS di seluruh sektor prioritas.\n"
      ],
      "metadata": {
        "id": "oqN5vE0Kp6Hf"
      }
    }
  ]
}